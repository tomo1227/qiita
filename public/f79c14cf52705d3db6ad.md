---
title: インタプリタ作成
tags:
  - Go
  - '#インタプリタ'
  - '#monkey'
private: true
updated_at: '2021-05-20T06:05:26+09:00'
id: f79c14cf52705d3db6ad
organization_url_name: null
slide: false
ignorePublish: false
---
#はじめに

##概要

インタプリタを一から作っていく。
使用する言語はGo言語である。

##Monkey

Monkeyという独自のプログラミング言語のインタプリタを作成する。

###Monkeyの特徴

* C言語風の構文
* 変数束縛
* 整数と真偽値
* 算術式
* 組み込み関数
* 第一級の高階関数
* クロージャ
* 文字列データ型
* 配列データ型
* ハッシュデータ型

###Monkeyの使用例

```
let age = 1; 
let name = "Monkey";
let result = 10 * (20 / 2);

let myArray = [1, 2, 3, 4, 5];  //配列

let thorsten = {"name": "Thorsten", "age":28}; //ハッシュ

myArray[0] // 1
thorsten["name"]  // "Thorsten"

let add = fn(a, b) { return a + b; };

let add = fn(a, b) { a + b; }; // returnの省略可

add(1, 2);　//関数呼び出し

//N番目のフィボナッチ数を返す関数
let fibonacci = fn(x) {
  if (x == 0) `
    0
  } else {
    if (x == 1) {
      1
    } else {
      fibonacci(x - 1) + fibonacci(x - 2);
    }
  }
}; 

//Monkeyは高階関数。すなわち、他の関数を引数として受け取ることができる。
let twice = fn(f, x) {
  return f(f(x));
};

let addTwo = fn(x) {
  return x + 2;
};

twice(addTwo, 2); // 6
```

###インタプリタの内容

* 字句解析器
* 構文解析器
* 抽象構文器(AST)
* 内部オブジェクトシステム
* 評価器


#字句解析

##字句解析とは

ソースコードをトークン列へ変換することを字句解析という。
字句解析は字句解析器(トークナイザー、スキャナー)によって行われる。

トークン列は小さな分類しやいデータ構造となっており、
構文解析器によって抽象構文器へと変換される。


###変換例

```:ソースコード
let x = 5 + 5;
```

```:トークン列
[
  LET,
  IDENTIFIER("x")
  EQUAL_SIGN,
  INTEGER(5),
  PLUS_SING,
  INTEGER(5),
  SEMICOLON
]
```


Pythonなどの言語と違い、Monkeyはホワイトスペースが
トークンとして出てこないので、ホワイトスペースの数は意味を持たない。

プロダクションで使えるような字句解析器では、行番号や列番号、ファイル名をトークンに付加することがある。
それはエラーメッセージで行番号などを出力するためである。(ここでは使用しない)

##トークンの定義

トークンには`タイプ`が必要である。
これにより整数、記号などを区別する。
それからトークンのリテラル値を保持するフィールドも必要である。
あとで「数」のトークンの値が分からなくなるのを防ぐ。

tokenパッケージにToken構造体とTokenType型を定義する。

```:token/token.go
package token
type TokenType string

type Token struct {
    Type    TokenType
    Literal string
}
```

TokenType型をstringとして定義した。
stringを使うことでヘルパー関数などを用意しなくても簡単にデバッグできる。


トークンタイプの種類は有限なので、TokenTypeを定数として定義する。
同じファイルに以下を追加する。

```:token/token.go
const (
    ILLEGAL = "ILLEGAL" // トークンが未知であることを示す
    EOF     = "EOF"     //ファイル終端(end of file)を示す

    // 識別子 +　リテラル
    IDENT = "IDENT" // add, foobar, x, y, ・・・
    INT   = "INT"   // 12434131

    // 演算子
    ASSIGN = "="
    PLUS   = "+"

    // デリミタ
    COMMA     = ","
    SEMICOLON = ";"

    LPAREN = "("
    RPAREN = ")"
    LBRACE = "{"
    RBRACE = "}"

    // キーワード
    FUNCTION = "FUNCTION"
    LET      = "LET"
)
```


##字句解析器(レキサー)

```:lexer/lexer_test.go
package lexer

import (
    "testing"

    "monkey/token"
)

func TestNextToken(t *testing.T) {
    input := `=+(){},;`

    test  := []struct {
        expectedType     token.TokenType
        expectedLiteral  string
    }{
        {token.ASSIGN,    "="},
        {token.PLUS,      "+"},
        {token.LPAREN,    "("},
        {token.RPAREN,    ")"},
        {token.LBRACE,    "{"},
        {token.RBRACE,    "}"},
        {token.COMMA,     ","},
        {token.SEMICOLON, ";"},
        {toekn.EOF,        ""},
    }

    l :=New(input)

    for i, tt := range tests {
        tok := l.NextToken()

        if tok.Type != tt.expectedType {
            t.Fatalf("test[%d] - tokentype wrong. expected=%q, got=%q",
                i, tt.expectedType, tok.Type)
        }

        if tok.Literal != tt.expectedLiteral {
            t.Fatalf("tests[%d] - literal wrong. expected=%q, got=%q",
                i, tt.expectedLiteral, tok.Literal)
        }
    }
}
```














































